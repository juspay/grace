AI_PROVIDER=litellm

# LiteLLM Configuration (if AI_PROVIDER=litellm)
LITELLM_API_KEY=
LITELLM_BASE_URL=http://localhost:4000/v1
LITELLM_MODEL_ID=qwen3-coder-480b

# Vertex AI Configuration (if AI_PROVIDER=vertex)
# Supports both Anthropic Claude and Google Gemini models
# VERTEX_AI_PROJECT_ID=your_project_id
# VERTEX_AI_LOCATION=us-central1
# VERTEX_AI_MODEL=claude-3-5-sonnet-v2@20241022

# Anthropic Direct API (if AI_PROVIDER=anthropic)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL_ID=claude-3-5-sonnet-20241022

# Note: Automatic fallback order: LiteLLM -> Anthropic -> Vertex AI

CUSTOM_INSTRUCTIONS_FILE=./custom_instructions.txt

SEARXNG_BASE_URL=http://localhost:32768

MAX_DEPTH=5
MAX_PAGES_PER_DEPTH=10
MAX_TOTAL_PAGES=50
CONCURRENT_PAGES=3
LINK_RELEVANCE_THRESHOLD=0.6
TIMEOUT_PER_PAGE_MS=30000
RESPECT_ROBOTS_TXT=true

ENABLE_DEEP_LINK_CRAWLING=true
MAX_LINKS_PER_PAGE=10
DEEP_CRAWL_DEPTH=2

# AI-Driven Research (recommended for better results)
AI_DRIVEN_CRAWLING=true  # Let AI decide which links to follow and when to stop
AI_LINK_RANKING=true     # Use AI to rank and prioritize links
AI_COMPLETENESS_CHECK=true  # Let AI assess if enough information is gathered

RESEARCH_DATA_DIR=./data
HISTORY_FILE=./data/research_history.json

RESULT_OUTPUT_DIR=../references

RESULT_OUTPUT_FORMAT="markdown,html"  # Options: markdown, html, json

IS_DEBUG=false
DEBUG_LOG_FILE=./logs/debug.log

# PROXY_LIST=http://proxy1:8080,http://proxy2:8080